# The Complete Pipeline

The entire FishNET pipeline revolves around getting images off of the FishNET hardware and analyzing the results with the software back-end.  The back-end is intended to be run separately from the camera hardware.  Strictly speaking there is nothing preventing you from running the back-end on the camera hardware aside from the computing power of the Pi.  For the purposes of this documentation, it is assumed that the back-end is run on a separate device.

```mermaid
flowchart LR
    A[FishNET Hardware captures video] --> B[Live streamed on Youtube]
    A --> C[Video is stored locally]
    C --> D[Video is offloaded by user]
    B & D--> E[Video analyzed by back-end]
    E --> F[Fish classifications and counts]
```

For convenience, the entire software back-end setup is explained and executed step by step in [this example back-end Google Colab notebook](https://colab.research.google.com/drive/1TVnzX5gFm9IsaTfBCYlGmHKqePYD7Azd?usp=sharing).  Once you load the notebook, create a copy by selecting *File > Save a copy in Drive*.  The included instructions should be enough to get you up and running.

For reference, the content of the notebook is included as static markdown below:

---
<div class="cell markdown" id="UWzCqjTxLXO2">
  
This notebook contains the AI back-end powering the FishNET project. It
includes the computer vision models to classify images of fish into the
five target species, and templates for running the backend on
pre-captured video or a live feed. For more information about the
project, see [the
docs](https://github.com/SVVSDICAI/fishNET-documentation). The purpose
of this notebook is to allow anyone to easily replicate the FishNET
system, or run the models on their custom data.

</div>

<div class="cell markdown" id="H5znkKbuNIDY">

#### Cloning the FishNET software back-end

The first step in using the FishNET back-end is to clone [the
repository](https://github.com/SVVSDICAI/FishNetStreamAnalyzer)
containing all of the analyzer code.

</div>

<div class="cell code" id="BJhyt7GhAFMX">

``` python
# clone the FishNET Stream Analyzer repository
%cd /content/
!rm -r FishNetStreamAnalyzer/ # WARNING this line will reset the repository to the latest version, any local changes will be lost
!git clone https://github.com/SVVSDICAI/FishNetStreamAnalyzer.git
```

</div>

<div class="cell markdown" id="gL1H7mFTNrx6">

### Forking the FishNET Template Database

The easiest way to store FishNET's results in the cloud is by storing
them in a github repository. In the future, the FishNET team plans to
migrate to [AWS s3 buckets](https://aws.amazon.com/s3/) for this
purpose, but at the project's current scale the above solution is
sufficient.

The following cells create a fork of a template database repository
using your GitHub account. For this to run successfully, please insert
your github username and access token in the second cell down:

-   set `GITHUB_USERNAME` to a string containing your GitHub username
-   set `os.environ['GH_TOKEN']` to a string containing your GitHub
    private access token
-   Access tokens can be generated by going to your account settings \>
    Developer Settings \> Personal access tokens \> Tokens (classic) \>
    Generate new token.
-   We recommend setting an expiration date on your access token,
    ensuring it will expire should you forget to delete it after using
    this notebook.
-   Once you insert your access token, do not make this notebook public,
    and delete the token if you plan to share the notebook with anyone.

In addition to identifying the species and rough count of fish in a
given location, the FishNET back-end stores links to images of fish that
it picks out from the data. These images are uploaded to Imgur using the
[Imgur API](https://apidocs.imgur.com/), and links to the images are
included in the results database. In order to use this functionality,
please create an Imgur API account, and follow the instructions to find
your IMGUR_CLIENT_ID. Please set `os.environ['IMGUR_CLIENT_ID']` in the
second cell down to this id stored in a string. The same security
measures should apply to this id as your github access token.

</div>

<div class="cell code" id="fe720xt-laZL">

``` python
# install the github cli command (which is used to create a fork of the Stream Capture repo)
!type -p curl >/dev/null || (sudo apt update && sudo apt install curl -y)
!curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo dd of=/usr/share/keyrings/githubcli-archive-keyring.gpg \
  && sudo chmod go+r /usr/share/keyrings/githubcli-archive-keyring.gpg \
  && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null \
  && sudo apt update \
  && sudo apt install gh -y
```

</div>

<div class="cell code" id="5moH7HcsxPVS">

``` python
# add your github credentials below
import os
GITHUB_USERNAME = '' # change this to your github username
os.environ['GH_TOKEN'] = 'ghp_...' # change this to your github access key

# an IMGUR API key is needed to save the images to public links in the Stream Capture repo
# you can generate such a key by following https://apidocs.imgur.com/#authorization-and-oauth
# specify your key below
os.environ['IMGUR_CLIENT_ID'] = ''
```

</div>

<div class="cell markdown" id="guDdc078RXrB">

Once you add your GitHub credentials in the above cell, the following
cell will use the GitHub API to create a fork of the official FishNET
results database repository under your account. This step only needs to
be run once. Each subsequent time you use this notebook you can skip
this step.

</div>

<div class="cell code" id="WSUhoWc3AxCy">

``` python
# create a fork of the FishNet Stream Capture repository to store the model's results
# THIS CELL MUST ONLY BE RUN ONCE TO CREATE THE FORK
%cd /content/FishNetStreamAnalyzer/
!rm -r FishNetStreamCapture/ # WARNING this line will reset the repository to the default template, any local changes will be lost

# login to the github cli and create a fork of the repository
!gh auth login --with-token {os.environ['GH_TOKEN']}
!gh auth status -t
!gh repo fork SVVSDICAI/FishNetStreamCapture --remote=true
```

</div>

<div class="cell markdown" id="85cyLKH3R5M8">

Next, the results database fork is cloned so that local changes can be
written to it by the FishNET back-end.

</div>

<div class="cell code" id="BQeS7YBWxt7E">

``` python
# clone the fork
%cd /content/FishNetStreamAnalyzer/
!rm -r FishNetStreamCapture/ # WARNING this line will reset the repository to the default template, any local changes will be lost
!git clone --branch template https://{GITHUB_USERNAME}:{os.environ['GH_TOKEN']}@github.com/{GITHUB_USERNAME}/FishNetStreamCapture.git

# add a description of the fork to the README.md file
%cd ./FishNetStreamCapture/
!echo "**This repository is a fork of the [FishNET Stream Capture](https://github.com/SVVSDICAI/FishNetStreamCapture.git) repository.  It is used to store the results of the FishNET AI back-end.**" >> README.md

# push the changes to test that the forked repository was created successfully
!git checkout -b master
!pip install git-python
from git import Repo

PATH_OF_GIT_REPO = r'.'
COMMIT_MESSAGE = "created fork of FishNET Stream Capture repository"

repo = Repo(PATH_OF_GIT_REPO)
repo.git.add(update=True)
repo.index.commit(COMMIT_MESSAGE)

origin = repo.remote(name="origin")
print("pushing changes...")
origin.push(refspec=repo.active_branch.name, set_upstream=True)
```

</div>

<div class="cell markdown" id="_O67mcyaSFim">

### Installing the necessary packages and importing the FishNET StreamCapture library

The FishNET back-end requires the following libraries in addition to
tensorflow (which is pre-installed on colab notebooks):

-   `pyimgur`
-   `colorama`
-   `pillow`
-   `yt_dlp` (optional, if you plan on analyzing a live stream)

All of the code needed to use the FishNET backend is located in the
library called `StreamCapture`. Importing this library will load the
[two Keras
models](https://github.com/SVVSDICAI/fishNET-documentation/blob/main/ImplementingTheModel.md),
and provide access to the `run_model` function. This function is
intended to be called sequentially over a range of video frames (which
it takes as input), and updates the results database as fish are
identified and classified.

</div>

<div class="cell code" id="gkVl6f112xVK">

``` python
# install the needed libraries
!pip install pyimgur colorama pillow yt_dlp
```

</div>

<div class="cell code" id="mYB9aH0X17B6">

``` python
# import StreamCapture
%cd /content/FishNetStreamAnalyzer/
import StreamCapture
```

</div>

<div class="cell markdown" id="HJiwaTrRUQeS">

## Example Usage: Analyzing Pre-recorded, Locally Stored Video

This code is intended to be used when you have set up the FishNET camera
[to record video and store it locally over a certian time
period](https://github.com/SVVSDICAI/fishNET-documentation/blob/main/recording.md).
Once the video clips have been offloaded from the camera, upload them to
the `FishNetStreamAnalyzer/clips/Deployment` directory in this notebook.
The following cell will run through each frame in each clip, adding all
results to the results database. This is a great plug-and-play option if
you already have lots of unreviewed underwater footage at your disposal.

</div>

<div class="cell code" id="zlWTHSNR3CUg">

``` python
import cv2
from PIL import Image, ImageFile, ImageOps

StreamCapture.SHOW_PREDICTION_IMGS = False

# try running FishNET!
try:
  # iterate over each frame in the video file captured locally on the camera pi
  for clip in sorted(os.listdir('./clips/Deployment')):
      video = './clips/Deployment/' + clip
      cap = cv2.VideoCapture(video)
      clip_date = clip.split('_')[1].split('.')[0] # just get the date from file name of the form clipN_[date].h264

      # iterate over the frames
      while cap.isOpened():
          # read the current frame
          ret, frame = cap.read()

          if not ret:
              break

          frame_image = Image.fromarray(frame)
          frame_image.convert('RGB').save('fish.png')
          # rotate the image
          #frame_image = frame_image.rotate(90)
          StreamCapture.run_model(frame_image)

      # release the video capture object
      cap.release()

except KeyboardInterrupt:
    print('exiting...')
```

</div>

<div class="cell markdown" id="gyOc5A54Ua_9">

## Example Usage: Analyzing a Live Stream Video

This code is intended to be used when you have set up the FishNET camera
[to livestream to a service like
Youtube](https://github.com/SVVSDICAI/fishNET-documentation/blob/main/livestreaming.md).
The following cell will fetch frames from the Youtube stream specified
in the `url` variable, and run them through the `run_model` function.

</div>

<div class="cell code" colab="{&quot;background_save&quot;:true}"
id="F3GGs-fJ5ett">

``` python
import cv2
import multiprocessing
import os
import shutil
import subprocess
import time
from PIL import Image, ImageFile, ImageOps
import yt_dlp

# define a function that downloads frames from the live stream on a separate thread
def start_download(url, ydl_opts):
    print('starting download')
    yt_dlp.YoutubeDL(ydl_opts).download([url])
    print('ending download')


# set up vidgear to capture images from the youtube stream
url = 'https://www.youtube.com/watch?v=lXzSU7ezjp8'

# define the options for downloading the video
ydl_opts = {
    'format': 'best[ext=mp4]',
    'quiet': True,
    'no_warnings': True,
    'outtmpl': './clips/live.mp4'
}

# remove previous downloads
if os.path.exists('./clips/live.mp4.part'):
    os.remove('./clips/live.mp4.part')
if os.path.exists('./clips/live.mp4'):
    os.remove('./clips/live.mp4')
if os.path.exists('./clips/saved.mp4'):
    os.remove('./clips/saved.mp4')

# start the download process
download_proc = multiprocessing.Process(target=start_download, args=(url, ydl_opts,))
download_proc.start()

# start with 2 seconds of video to run the model on
while not os.path.exists('./clips/live.mp4.part'):
  pass
time.sleep(2)
shutil.copyfile('./clips/live.mp4.part', './clips/saved.mp4')

StreamCapture.SHOW_PREDICTION_IMGS = False

# try running FishNET!
try:
    # open the downloaded video using OpenCV
    last_frame = 1
    cap = cv2.VideoCapture('./clips/saved.mp4')
    cap.set(cv2.CAP_PROP_POS_FRAMES, last_frame)

    while True:
        # read from the downloaded portion of the live stream
        ret, frame = cap.read() # get the latest frame from the live stream

        # if there are no more frames, copy the contents of live.mp4 to saved.mp4
        if not ret:
            shutil.copyfile('./clips/live.mp4.part', './clips/saved.mp4')

            # reopen the file with cv2 making sure to resume at the last frame
            last_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            cap = cv2.VideoCapture('./clips/saved.mp4')
            cap.set(cv2.CAP_PROP_POS_FRAMES, last_frame)
            continue

        frame_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        frame_image.convert('RGB').save('fish.png')
        StreamCapture.run_model(frame_image)

except KeyboardInterrupt:
    cap.release()
    download_proc.terminate()
```

</div>

<div class="cell markdown" id="yc4UeshyWZfO">

## Interpreting the Results

FishNET's results are stored in the fork of the results database that
you created above. Open this repository in GitHub, or locally in the
notebook file browser. Open or download the `convertcsv.csv` file. Each
row in this data table shows a fish that was detected by the model. Each
row has a link to the corresponding image containing the fish, and its
predicted species. Using this data you can get an idea of the species of
fish in a given location:

![CSV
preview](https://github.com/SVVSDICAI/fishNET-documentation/blob/main/Media/csv_preview.png?raw=true)

The repository also contains a graph of fish counted over time, called
`graph.png`. The counts are estimated values as the current iteration of
this model does not include object tracking. This means that no
information about the fish is retained between frames. In short, it has
no way of knowing if the fish in one frame is the same as the fish in
another frame. We are working on a more advanced model that will have
some of these capabilities. To get around this restriction, when the
current model sees a fish, it will only increment the counter if there
was no fish in the previous frame. This way, a fish that stays in view
for several frames is only counted once. With this in mind, the above
counts are a good estimate for the number of fish on a given day, but
not an exact count:

![graph](https://github.com/SVVSDICAI/FishNetStreamCapture/blob/master/graph.png?raw=true)

Our hope is that the FishNET project can help experts make informed
policy and conservation decisions with the help of AI.

</div>
---